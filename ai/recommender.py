import streamlit as st
import google.generativeai as genai
import os
from typing import List, Dict
import json
from dotenv import load_dotenv
import requests 
from bs4 import BeautifulSoup 
from ai.prompts import get_segment_recommendation_prompt
from itertools import groupby # [â˜…ìˆ˜ì •] ê·¸ë£¹í™”ë¥¼ ìœ„í•´ ì¶”ê°€
import math # [â˜…ìˆ˜ì •] 1ì°¨ ì¶”ì²œ ê°œìˆ˜ ê³„ì‚°ì„ ìœ„í•´ ì¶”ê°€

load_dotenv()

class AISegmentRecommender:
    def __init__(self, data_manager):
        self.data_manager = data_manager
        self.segments_data = data_manager.load_segments()
        self.api_key = os.getenv('GEMINI_API_KEY')
        self.model = None
        self.gemini_available = False
        self._initialize_gemini()
    
    def _initialize_gemini(self):
        if not self.api_key:
            st.error("âŒ Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— GEMINI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
            return
        try:
            genai.configure(api_key=self.api_key)
            try:
                self.model = genai.GenerativeModel('gemini-2.0-flash')
            except:
                self.model = genai.GenerativeModel('gemini-pro')
            self.gemini_available = True
        except Exception as e:
            st.error(f"âŒ Gemini API ì„¤ì • ì˜¤ë¥˜: {str(e)}")
            self.gemini_available = False
    
    # [â˜…ìˆ˜ì •] 2-Stage (ê·¸ë£¹ë³„ í˜¸ì¶œ) ë°©ì‹ìœ¼ë¡œ ë¡œì§ ì „ë©´ ìˆ˜ì •
    def recommend_segments(self, product_name: str, website_url: str, num_recommendations: int = 3) -> List[Dict]:
        
        if not product_name.strip() and not website_url.strip():
            st.error("âŒ 'ì œí’ˆëª…' ë˜ëŠ” 'ì œí’ˆ URL*'ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return []
            
        if not self.gemini_available or not self.model:
            st.error("âŒ Gemini AIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []
            
        scraped_text = ""
        if website_url:
            with st.spinner(f"ğŸŒ {website_url} ì›¹í˜ì´ì§€ ë¶„ì„ ì¤‘..."):
                scraped_text = self._fetch_url_content(website_url)
                if not scraped_text:
                    st.warning("âš ï¸ ì›¹ì‚¬ì´íŠ¸ ë‚´ìš©ì„ ìë™ìœ¼ë¡œ ì½ì–´ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì œí’ˆëª…/URLë¡œë§Œ ë¶„ì„í•©ë‹ˆë‹¤.")

        try:
            # 1. ëª¨ë“  ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ ë¡œë“œ (4-depth êµ¬ì¡°)
            available_segments_info = self._get_available_segments_info()
            if not available_segments_info:
                st.error("âŒ ì„¸ê·¸ë¨¼íŠ¸ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (data/segments.json)")
                return []

            # 2. ì„¸ê·¸ë¨¼íŠ¸ë¥¼ (ëŒ€ë¶„ë¥˜, ì¤‘ë¶„ë¥˜, ì†Œë¶„ë¥˜) í‚¤ë¡œ ê·¸ë£¹í™”
            def get_group_key(segment):
                return (
                    segment.get('ëŒ€ë¶„ë¥˜', 'N/A'), 
                    segment.get('ì¤‘ë¶„ë¥˜', 'N/A'), 
                    segment.get('ì†Œë¶„ë¥˜', 'N/A') # null(None) ê°’ë„ ê³ ìœ  í‚¤ë¡œ ì‚¬ìš©ë¨
                )
            
            # ì •ë ¬ í›„ ê·¸ë£¹í™”
            segments_sorted = sorted(available_segments_info, key=get_group_key)
            grouped_segments = {k: list(g) for k, g in groupby(segments_sorted, key=get_group_key)}
            
            num_groups = len(grouped_segments)
            st.info(f"ğŸ” AI íƒ€ê²Ÿ ë¶„ì„ ì‹œì‘... (ì´ {len(available_segments_info)}ê°œ ì„¸ê·¸ë¨¼íŠ¸, {num_groups}ê°œ ê·¸ë£¹ ë¶„ì„)")

            all_recommendations = []
            
            # [â˜…ìˆ˜ì •] ê·¸ë£¹ë³„ë¡œ AIì—ê²Œ 1ì°¨ ì¶”ì²œì„ ëª‡ ê°œ ë°›ì„ì§€ ê²°ì • (ìµœì†Œ 2ê°œ, ìµœëŒ€ 5ê°œ)
            # ê·¸ë£¹ì´ ë§ì„ìˆ˜ë¡(20ê°œ ì´ìƒ) ê·¸ë£¹ë‹¹ 2-3ê°œ, ê·¸ë£¹ì´ ì ìœ¼ë©´ 4-5ê°œ
            num_per_group = max(2, min(5, math.ceil(100 / max(1, num_groups))))


            # 3. ê° ê·¸ë£¹ë³„ë¡œ AI í˜¸ì¶œ (2-Stageì˜ 1ë‹¨ê³„)
            for i, (group_key, segments_in_group) in enumerate(grouped_segments.items()):
                
                group_name = " > ".join(filter(None, [k if k != 'N/A' else None for k in group_key]))
                
                with st.spinner(f"ğŸ¤– AI ë¶„ì„ ì¤‘... ({i+1}/{num_groups}) : '{group_name}' ê·¸ë£¹ ({len(segments_in_group)}ê°œ)"):
                    
                    # [â˜…ìˆ˜ì •] ê·¸ë£¹ë³„ 1ì°¨ ì¶”ì²œ ê°œìˆ˜ ë™ì  ì¡°ì ˆ
                    # ê·¸ë£¹ ë‚´ ì„¸ê·¸ë¨¼íŠ¸ê°€ 5ê°œ ë¯¸ë§Œì´ë©´ ì „ë¶€, ì•„ë‹ˆë©´ num_per_group ê°œìˆ˜ë§Œí¼
                    num_to_recommend_group = min(len(segments_in_group), num_per_group)

                    ai_response = self._recommend_with_gemini(
                        product_name, website_url, scraped_text, 
                        segments_in_group, # [â˜…ìˆ˜ì •] ì „ì²´ê°€ ì•„ë‹Œ ê·¸ë£¹ ë¦¬ìŠ¤íŠ¸ ì „ë‹¬
                        num_to_recommend=num_to_recommend_group
                    )
                
                if not ai_response:
                    segments_from_ai = []
                else:
                    # [â˜…ìˆ˜ì •] ì œí’ˆ ì´í•´ëŠ” ì²« ë²ˆì§¸ ê·¸ë£¹ ë¶„ì„ ì‹œ 1íšŒë§Œ í‘œì‹œ
                    if i == 0:
                        product_understanding = ai_response.get("product_understanding")
                        if product_understanding:
                            st.info(f"**ğŸ’¡ AIê°€ ì´í•´í•œ ì œí’ˆ:** {product_understanding}")
                    segments_from_ai = ai_response.get("recommended_segments", [])

                if not segments_from_ai:
                    continue

                # AI ì‘ë‹µ(ì´ë¦„, ì´ìœ , ì ìˆ˜)ê³¼ ì›ë³¸ ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´(ì„¤ëª…, ê²½ë¡œ ë“±)ë¥¼ ë³‘í•©
                segment_names = [s.get("name") for s in segments_from_ai if s.get("name")]
                enriched_info_map = {
                    s.get("name"): {
                        "reason": s.get("reason", "ì¶”ì²œ ì´ìœ ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."),
                        "confidence_score": s.get("confidence_score", 50),
                        "key_factors": s.get("key_factors", [])
                    }
                    for s in segments_from_ai if s.get("name")
                }
                
                # ì›ë³¸ ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ì—ì„œ AIê°€ ì¶”ì²œí•œ ê²ƒë§Œ í•„í„°ë§
                recommended_segments_group = self._get_segments_by_names(segment_names, segments_in_group)
                
                # ë³‘í•©
                for seg in recommended_segments_group:
                    seg_name = seg['name']
                    if seg_name in enriched_info_map:
                        seg['reason'] = enriched_info_map[seg_name]['reason']
                        seg['confidence_score'] = enriched_info_map[seg_name]['confidence_score']
                        seg['key_factors'] = enriched_info_map[seg_name]['key_factors']
                
                all_recommendations.extend(recommended_segments_group)

            if not all_recommendations:
                 st.warning("âš ï¸ AIê°€ ì¶”ì²œ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê¸°ë³¸ ì¶”ì²œì„ ì œê³µí•©ë‹ˆë‹¤.")

            # 4. 1ì°¨ ì·¨í•©ëœ ëª¨ë“  ì¶”ì²œ ê²°ê³¼ë¥¼ ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬ (2-Stageì˜ 2ë‹¨ê³„)
            all_recommendations.sort(key=lambda x: x.get('confidence_score', 0), reverse=True)
            
            # ì¤‘ë³µ ì œê±° (ì´ë¦„ ê¸°ì¤€)
            final_recommendations = []
            seen_names = set()
            for seg in all_recommendations:
                if seg['name'] not in seen_names:
                    final_recommendations.append(seg)
                    seen_names.add(seg['name'])

            # 5. Fallback ë¡œì§ (í•„ìš”ì‹œ)
            num_to_pad = num_recommendations - len(final_recommendations)
            if num_to_pad > 0:
                existing_names = [seg['name'] for seg in final_recommendations]
                fallback_segments = [seg for seg in available_segments_info if seg['name'] not in existing_names]
                
                # Fallback í›„ë³´ë„ ì ìˆ˜ìˆœ(ê¸°ë³¸ê°’)ì´ë‚˜ ë‹¤ë¥¸ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ë©´ ì¢‹ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœ ì¶”ê°€
                for i in range(min(num_to_pad, len(fallback_segments))):
                    fallback_seg = fallback_segments[i].copy()
                    fallback_seg['reason'] = "ì œí’ˆê³¼ ê´€ë ¨ì„±ì´ ë†’ì€ ê¸°ë³¸ ì„¸ê·¸ë¨¼íŠ¸ì…ë‹ˆë‹¤."
                    fallback_seg['confidence_score'] = 60 # ê¸°ë³¸ ì¶”ì²œ ì ìˆ˜
                    fallback_seg['key_factors'] = ["ê¸°ë³¸ ì¶”ì²œ"]
                    final_recommendations.append(fallback_seg)
            
            st.success(f"âœ… AI íƒ€ê²Ÿ ë¶„ì„ ì™„ë£Œ! (ì´ {len(final_recommendations)}ê°œ í›„ë³´ ì¤‘ ìƒìœ„ {num_recommendations}ê°œ)")
            
            # 6. ìµœì¢… ê°œìˆ˜ë§Œí¼ ì˜ë¼ì„œ ë°˜í™˜
            return final_recommendations[:num_recommendations]

        except Exception as e:
            st.error(f"âŒ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return []
    
    def _fetch_url_content(self, url: str) -> str:
        try:
            headers = {'User-Agent': 'Mozilla/5.0'}
            response = requests.get(url, headers=headers, timeout=5)
            response.raise_for_status()
            soup = BeautifulSoup(response.text, 'html.parser')
            meta_desc = soup.find('meta', attrs={'name': 'description'})
            if meta_desc and meta_desc.get('content'):
                return meta_desc.get('content').strip()
            for tag in soup.find_all(['main', 'article']):
                text = tag.get_text(separator=' ', strip=True)
                if len(text) > 100:
                    return text[:1500]
            body_text = soup.body.get_text(separator=' ', strip=True)
            return body_text[:1500]
        except:
            return ""
    
    # [â˜…ìˆ˜ì •] available_segments_info: ì´ì œ ì „ì²´ê°€ ì•„ë‹Œ 'íŠ¹ì • ê·¸ë£¹'ì˜ ì„¸ê·¸ë¨¼íŠ¸ ë¦¬ìŠ¤íŠ¸
    def _recommend_with_gemini(self, product_name: str, website_url: str, scraped_text: str, available_segments_info: List[Dict], num_to_recommend: int) -> Dict:
        if not available_segments_info:
            # ê·¸ë£¹ì´ ë¹„ì–´ìˆëŠ” ê²½ìš°ëŠ” ì˜¤ë¥˜ê°€ ì•„ë‹ˆë¯€ë¡œ ë¹ˆ dict ë°˜í™˜
            return {}
        
        segments_with_desc = []
        for seg in available_segments_info:
            # [â˜…ìˆ˜ì •] ìƒˆ JSON í‚¤ ì‚¬ìš©
            seg_str = f"- {seg.get('name', 'N/A')} (ì„¤ëª…: {seg.get('description', 'N/A')}"
            
            advertisers = seg.get('recommended_advertisers')
            if advertisers and pd.notna(advertisers):
                clean_advertisers = str(advertisers).replace('\n', ', ')
                seg_str += f", ì¶”ì²œ ê´‘ê³ ì£¼: {clean_advertisers}"
            seg_str += ")"
            segments_with_desc.append(seg_str)
        
        segments_list_str = "\n".join(segments_with_desc)
        
        prompt = get_segment_recommendation_prompt(
            product_name, website_url, scraped_text, segments_list_str, 
            num_to_recommend=num_to_recommend
        )
        
        try:
            # [â˜…ìˆ˜ì •] 2-Stageì—ì„œëŠ” spinnerë¥¼ ì™¸ë¶€(recommend_segments)ì—ì„œ ê´€ë¦¬
            response = self.model.generate_content(prompt)
            if not response or not response.text:
                raise ValueError("Gemini APIì—ì„œ ë¹ˆ ì‘ë‹µì„ ë°›ì•˜ìŠµë‹ˆë‹¤.")
            raw_response_text = response.text
        except Exception as e:
            # ê°œë³„ ê·¸ë£¹ ì‹¤íŒ¨ ì‹œ st.error ëŒ€ì‹  ë¡œê¹…/ë¬´ì‹œ
            print(f"âŒ Gemini API í˜¸ì¶œ ì‹¤íŒ¨ (ê·¸ë£¹): {str(e)}")
            return {}
        
        try:
            cleaned_text = raw_response_text.strip().replace("```json\n", "").replace("\n```", "").strip()
            parsed_data = json.loads(cleaned_text)
            if not isinstance(parsed_data, dict):
                raise ValueError("AI ì‘ë‹µì´ ë”•ì…”ë„ˆë¦¬ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
            return parsed_data
        except json.JSONDecodeError:
            print(f"âŒ AIê°€ ìœ íš¨í•˜ì§€ ì•Šì€ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí–ˆìŠµë‹ˆë‹¤: {cleaned_text}")
            return {}
    
    # [â˜…ìˆ˜ì •] ë¡œì§ì€ ë™ì¼, ì…ë ¥ë˜ëŠ” available_segmentsê°€ ê·¸ë£¹ ë¦¬ìŠ¤íŠ¸ì¼ ë¿
    def _get_segments_by_names(self, segment_names: List[str], available_segments: List[Dict]) -> List[Dict]:
        recommended_segments = []
        available_names = {seg['name']: seg for seg in available_segments}
        for name in segment_names:
            if name in available_names:
                recommended_segments.append(available_names[name].copy())
        return recommended_segments
    
    # [â˜…ìˆ˜ì •] ìƒˆ 4-Depth JSON êµ¬ì¡°ë¥¼ íŒŒì‹±í•˜ë„ë¡ ìˆ˜ì •
    def _get_available_segments_info(self) -> List[Dict]:
        if 'data' not in self.segments_data or not isinstance(self.segments_data['data'], list):
            return []
            
        segments_info = []
        for segment in self.segments_data['data']:
            if not isinstance(segment, dict):
                continue
            
            # CSVì˜ nullì„ Noneìœ¼ë¡œ ì²˜ë¦¬
            cat1 = segment.get('ëŒ€ë¶„ë¥˜')
            cat2 = segment.get('ì¤‘ë¶„ë¥˜')
            cat3 = segment.get('ì†Œë¶„ë¥˜')
            name = segment.get('name', 'N/A')
            
            if cat3 and pd.notna(cat3) and cat3.lower() != 'null':
                full_path = f"{cat1} > {cat2} > {cat3} > {name}"
            else:
                full_path = f"{cat1} > {cat2} > {name}"

            # ìƒˆ êµ¬ì¡°ì— ë§ê²Œ ë³µì‚¬
            seg_copy = segment.copy()
            seg_copy['full_path'] = full_path
            # í‚¤ ì´ë¦„ ì¼ê´€ì„± ìœ ì§€ (description, recommended_advertisersëŠ” CSVì™€ ë™ì¼)
            seg_copy['description'] = segment.get('description', '')
            seg_copy['recommended_advertisers'] = segment.get('recommended_advertisers', '')
            
            segments_info.append(seg_copy)
            
        return segments_info
    
    # [â˜…ì œê±°] _flatten_segments í•¨ìˆ˜ëŠ” ë” ì´ìƒ í•„ìš”í•˜ì§€ ì•ŠìŒ
    
    def display_recommendations(self, recommended_segments: List[Dict]):
        """ì¶”ì²œ ê²°ê³¼ í‘œì‹œ (st.expander ì‚¬ìš©, UI ìˆ˜ì •)"""
        if not recommended_segments:
            st.warning("âŒ ì¶”ì²œí•  ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return
        
        st.markdown("""
        <style>
        .tag-box {
            display: inline-block;
            background-color: #28a745;
            color: white;
            padding: 3px 10px;
            border-radius: 15px;
            font-size: 0.9em;
            font-weight: bold;
            margin-right: 5px;
            margin-top: 5px;
            margin-bottom: 5px;
        }
        </style>
        """, unsafe_allow_html=True)

        for i, segment in enumerate(recommended_segments, 1):
            score = segment.get('confidence_score', 0)
            
            # [â˜…ìˆ˜ì •] full_path í‚¤ ì‚¬ìš©
            title_text = f"**{i}. {segment.get('full_path', segment.get('name', 'N/A'))}**"
            
            if score < 60:
                 title_text += " (ê¸°ë³¸ ì¶”ì²œ)"

            with st.expander(title_text, expanded=True):
                
                if score >= 60:
                    st.markdown(f"**ì í•©ë„: <span style='color:#d9534f; font-weight:bold; font-size: 1.1em;'>{score}ì </span>**", unsafe_allow_html=True)
                    reason_prefix = "ğŸ’¡ AI ì¶”ì²œ ì‚¬ìœ :"
                else:
                    st.markdown(f"**ì í•©ë„:** {score}ì ")
                    reason_prefix = "â„¹ï¸ ê¸°ë³¸ ì¶”ì²œ ì‚¬ìœ :"
                
                # [â˜…ìˆ˜ì •] description í‚¤ ì‚¬ìš©
                if segment.get('description'):
                    st.write(f"**ğŸ“‹ ì„¤ëª…:** {segment['description']}")
                
                # 'ì¶”ì²œ ê´‘ê³ ì£¼' í•­ëª©ì€ ì´ì „ì— ì œê±° ìš”ì²­ë¨
                # if segment.get('recommended_advertisers'):
                #     st.write(f"**ğŸ¯ ì¶”ì²œ ê´‘ê³ ì£¼:** {segment['recommended_advertisers']}")

                if segment.get('key_factors'):
                    tags_html = "".join([f"<span class='tag-box'>{factor}</span>" for factor in segment['key_factors']])
                    st.markdown(f"**ğŸ”‘ í•µì‹¬ ë§¤ì¹­ ìš”ì†Œ:** {tags_html}", unsafe_allow_html=True)

                st.divider()

                if segment.get('reason'):
                    if score >= 60:
                        st.success(f"**{reason_prefix}** {segment['reason']}")
                    else:
                        st.info(f"**{reason_prefix}** {segment['reason']}")