# ai/recommender.py
import streamlit as st
import google.generativeai as genai
import os
from typing import List, Dict, Set
import json
from dotenv import load_dotenv
import requests 
from bs4 import BeautifulSoup 
from ai.prompts import (
    get_segment_recommendation_prompt, 
    get_segment_filtering_prompt,
    get_mapping_and_understanding_prompt # [â˜…ìˆ˜ì •] 0ë‹¨ê³„ í”„ë¡¬í”„íŠ¸ ì„í¬íŠ¸
)
import pandas as pd
import time # 429 ì˜¤ë¥˜(ì¬ì‹œë„/ì§€ì—°) ë°©ì§€ë¥¼ ìœ„í•´ time ì„í¬íŠ¸
import re # [â˜…ìˆ˜ì •] í‚¤ì›Œë“œ ì¶”ì¶œì„ ìœ„í•´ re ì„í¬íŠ¸

load_dotenv()

class AISegmentRecommender:
    def __init__(self, data_manager):
        self.data_manager = data_manager
        self.segments_data = data_manager.load_segments()
        self.api_key = os.getenv('GEMINI_API_KEY')
        self.model = None
        self.gemini_available = False
        self._initialize_gemini()
    
    def _initialize_gemini(self):
        if not self.api_key:
            st.error("âŒ Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— GEMINI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
            return
        try:
            genai.configure(api_key=self.api_key)
            try:
                # [â˜…ìˆ˜ì •] 404 ì˜¤ë¥˜ í•´ê²°: 'models/' ì ‘ë‘ì‚¬ ì œê±° (ì‚¬ì¥ë‹˜ ì§€ì‹œ)
                # 1ìˆœìœ„: 'ê°€ì¥ ë¹ ë¥¸ 2.0 flash'
                self.model = genai.GenerativeModel('gemini-2.0-flash')
            except:
                # [â˜…ìˆ˜ì •] 1ìˆœìœ„ ì‹¤íŒ¨ ì‹œ 2ìˆœìœ„: 'pro'
                self.model = genai.GenerativeModel('gemini-2.0-pro')
            self.gemini_available = True
            st.success(f"âœ… AI ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {self.model.model_name}")
        except Exception as e:
            st.error(f"âŒ Gemini API ì„¤ì • ì˜¤ë¥˜: {str(e)}")
            st.error("ai/recommender.py 32~37 ë¼ì¸ì˜ ëª¨ë¸ ì´ë¦„ì„ 'gemini-2.0-flash' / 'gemini-2.0-pro'ë¡œ í™•ì¸í•˜ì„¸ìš”.")
            self.gemini_available = False

    def _generate_with_retry(self, prompt: str, max_retries: int = 3) -> str:
        """
        Gemini API í˜¸ì¶œ ì‹œ 429 ì˜¤ë¥˜(í• ë‹¹ëŸ‰)ê°€ ë°œìƒí•˜ë©´
        ìë™ìœ¼ë¡œ ì¬ì‹œë„í•˜ëŠ” ë¡œì§ (Exponential Backoff)
        """
        retries = 0
        while retries < max_retries:
            try:
                response = self.model.generate_content(prompt)
                if not response or not response.text:
                    raise ValueError("Gemini APIì—ì„œ ë¹ˆ ì‘ë‹µì„ ë°›ì•˜ìŠµë‹ˆë‹¤.")
                return response.text # ì„±ê³µ ì‹œ ì‘ë‹µ í…ìŠ¤íŠ¸ ë°˜í™˜
            
            except Exception as e:
                if "429 Resource exhausted" in str(e) and retries < max_retries - 1:
                    retries += 1
                    wait_time = 2 ** retries 
                    st.warning(f"âš ï¸ API í• ë‹¹ëŸ‰(429) ì´ˆê³¼. {wait_time}ì´ˆ í›„ ì¬ì‹œë„... ({retries}/{max_retries})")
                    time.sleep(wait_time)
                else:
                    raise e 
        
        raise Exception("API í• ë‹¹ëŸ‰ ì´ˆê³¼. ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨.")

    # [â˜…ìˆ˜ì •] 'ì‹œë§¨í‹± í•˜ì´ë¸Œë¦¬ë“œ' ë¡œì§ìœ¼ë¡œ ì „ë©´ ìˆ˜ì •
    def recommend_segments(self, product_name: str, website_url: str, num_recommendations: int = 3) -> List[Dict]:
        
        if not product_name.strip() and not website_url.strip():
            st.error("âŒ 'ì œí’ˆëª…' ë˜ëŠ” 'ì œí’ˆ URL*'ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return []
            
        if not self.gemini_available or not self.model:
            st.error("âŒ Gemini AIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []
            
        # --- 0-1. URL ìŠ¤í¬ë˜í•‘ ---
        scraped_text = ""
        if website_url:
            with st.spinner(f"ğŸŒ {website_url} ì›¹í˜ì´ì§€ ë¶„ì„ ì¤‘..."):
                scraped_text = self._fetch_url_content(website_url)
                if not scraped_text:
                    st.warning("âš ï¸ ì›¹ì‚¬ì´íŠ¸ ë‚´ìš©ì„ ìë™ìœ¼ë¡œ ì½ì–´ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì œí’ˆëª…/URLë¡œë§Œ ë¶„ì„í•©ë‹ˆë‹¤.")

        try:
            # 1. ëª¨ë“  ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ ë° DB í‚¤ì›Œë“œ ë¡œë“œ
            all_segments_info = self._get_available_segments_info()
            if not all_segments_info:
                st.error("âŒ ì„¸ê·¸ë¨¼íŠ¸ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (data/segments.json)")
                return []
            
            db_keywords_set = self._extract_db_keywords(all_segments_info)
            db_keywords_list_str = ", ".join(sorted(list(db_keywords_set)))

            
            # --- [â˜…ìˆ˜ì •] 0-2. AI ì œí’ˆ ì´í•´ + í‚¤ì›Œë“œ ë§¤í•‘ (0ë‹¨ê³„) ---
            product_understanding = ""
            mapped_keywords = []
            with st.spinner("ğŸ¤– AI ë¶„ì„ ì¤‘ (0/2): ì œí’ˆ ë¶„ì„ ë° DB í‚¤ì›Œë“œ ë§¤í•‘ ì¤‘..."):
                try:
                    mapping_json = self._get_mapping_and_understanding(
                        product_name, website_url, scraped_text, db_keywords_list_str
                    )
                    product_understanding = mapping_json.get("product_understanding", "")
                    mapped_keywords = mapping_json.get("mapped_keywords", [])
                except Exception as e:
                    st.warning(f"âš ï¸ AI 0ë‹¨ê³„(ë§¤í•‘) ì‹¤íŒ¨: {e}")
            
            if not product_understanding:
                product_understanding = f"ì œí’ˆëª…: {product_name} (AI ìë™ ë¶„ì„ ì‹¤íŒ¨)"
                st.warning("AIê°€ ì œí’ˆì„ ìë™ìœ¼ë¡œ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì œí’ˆëª…ìœ¼ë¡œ ë¶„ì„ì„ ì‹œë„í•©ë‹ˆë‹¤.")

            st.info(f"**ğŸ’¡ AIê°€ ì´í•´í•œ ì œí’ˆ:** {product_understanding}")
            if mapped_keywords:
                 st.info(f"**ğŸ”‘ AIê°€ ë§¤í•‘í•œ DB í‚¤ì›Œë“œ:** {', '.join(mapped_keywords)}")

            # --- [â˜…ìˆ˜ì •] Python: 'Aê¸‰ í›„ë³´' ì„ ë³„ ---
            a_class_segments, remaining_segments = self._get_a_class_segments(
                mapped_keywords, all_segments_info
            )
            
            if a_class_segments:
                st.success(f"âœ… 'Aê¸‰ í›„ë³´' {len(a_class_segments)}ê°œë¥¼ ìš°ì„  í™•ë³´í–ˆìŠµë‹ˆë‹¤.")

            # --- 1ë‹¨ê³„: í•„í„°ë§ (Bê¸‰ í›„ë³´ ì„ ë³„) ---
            num_to_filter = max(0, 40 - len(a_class_segments)) # 40ê°œë¥¼ ì±„ìš°ê¸° ìœ„í•œ Bê¸‰ í›„ë³´ ìˆ˜
            b_class_candidates = []
            
            if remaining_segments and num_to_filter > 0:
                with st.spinner(f"ğŸ¤– AI ë¶„ì„ ì¤‘ (1/2): ë‚˜ë¨¸ì§€ {len(remaining_segments)}ê°œ ì¤‘ Bê¸‰ í›„ë³´ ì„ ë³„ ì¤‘..."):
                    candidate_names = self._filter_with_gemini(
                        product_understanding, 
                        remaining_segments, # [â˜…ìˆ˜ì •] Aê¸‰ì„ ì œì™¸í•œ ë¦¬ìŠ¤íŠ¸ ì „ë‹¬
                        num_to_filter=num_to_filter
                    )
                    b_class_candidates = self._get_segments_by_names(candidate_names, remaining_segments)
            
            # --- 2ë‹¨ê³„: ì¬ì •ë ¬ (Aê¸‰ + Bê¸‰) ---
            
            # [â˜…ìˆ˜ì •] Aê¸‰ í›„ë³´(ì‚¬ì¥ë‹˜ ì •ë‹µ) + Bê¸‰ í›„ë³´(AI ì¶”ì²œ) = ìµœì¢… í›„ë³´êµ°
            final_candidate_list = a_class_segments + b_class_candidates
            
            if not final_candidate_list:
                st.warning("âš ï¸ AIê°€ ì¶”ì²œ í›„ë³´ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê¸°ë³¸ ì¶”ì²œì„ ì œê³µí•©ë‹ˆë‹¤.")
                final_candidate_list = all_segments_info[:20] # ë¹„ìƒì‹œ ì „ì²´ì—ì„œ 20ê°œ

            with st.spinner(f"ğŸ¤– AI ë¶„ì„ ì¤‘ (2/2): A/Bê¸‰ í›„ë³´ {len(final_candidate_list)}ê°œ ì •ë°€ ë¶„ì„ ë° ìˆœìœ„ ê²°ì • ì¤‘..."):
                ai_response = self._recommend_with_gemini(
                    product_understanding, 
                    final_candidate_list, # [â˜…ìˆ˜ì •] A+B ë¦¬ìŠ¤íŠ¸ ì „ë‹¬
                    num_to_recommend=num_recommendations
                )

            if not ai_response:
                segments_from_ai = []
            else:
                segments_from_ai = ai_response.get("recommended_segments", [])

            if not segments_from_ai:
                 st.warning("âš ï¸ AIê°€ 2ë‹¨ê³„ ì¶”ì²œ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê¸°ë³¸ ì¶”ì²œì„ ì œê³µí•©ë‹ˆë‹¤.")

            # --- AI ì‘ë‹µ(ì´ë¦„, ì´ìœ , ì ìˆ˜)ê³¼ ì›ë³¸ ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´(ì„¤ëª…, ê²½ë¡œ ë“±)ë¥¼ ë³‘í•© ---
            segment_names_from_ai = [s.get("name") for s in segments_from_ai if s.get("name")]
            enriched_info_map = {
                s.get("name"): {
                    "reason": s.get("reason", "ì¶”ì²œ ì´ìœ ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."),
                    "confidence_score": s.get("confidence_score", 50),
                    "key_factors": s.get("key_factors", [])
                }
                for s in segments_from_ai if s.get("name")
            }
            
            all_recommendations = []
            for name in segment_names_from_ai:
                seg_data = next((s for s in final_candidate_list if s.get('name') == name), None)
                if seg_data:
                    seg_copy = seg_data.copy()
                    if name in enriched_info_map:
                        seg_copy['reason'] = enriched_info_map[name]['reason']
                        seg_copy['confidence_score'] = float(enriched_info_map[name]['confidence_score'])
                        seg_copy['key_factors'] = enriched_info_map[name]['key_factors']
                    all_recommendations.append(seg_copy)

            # (â˜…ì •ë ¬ ë²„ê·¸ ìˆ˜ì •â˜…) ì ìˆ˜(ìˆ«ì)ë¡œ ë‹¤ì‹œ ì •ë ¬
            all_recommendations.sort(key=lambda x: float(x.get('confidence_score', 0)), reverse=True)
            
            # --- ì¤‘ë³µ ì œê±° ë° Fallback ---
            final_recommendations = []
            seen_names = set()
            for seg in all_recommendations:
                if seg['name'] not in seen_names and float(seg.get('confidence_score', 0)) > 50:
                    final_recommendations.append(seg)
                    seen_names.add(seg['name'])

            # 5. Fallback ë¡œì§ (í•„ìš”ì‹œ)
            num_to_pad = num_recommendations - len(final_recommendations)
            if num_to_pad > 0:
                existing_names = [seg['name'] for seg in final_recommendations]
                # [â˜…ìˆ˜ì •] Fallback í›„ë³´ëŠ” Aê¸‰, Bê¸‰ì´ ì•„ë‹Œ *ì „ì²´* ë¦¬ìŠ¤íŠ¸ì—ì„œ ì°¾ì•„ì•¼ í•¨
                fallback_segments = [seg for seg in all_segments_info if seg['name'] not in existing_names]
                
                for i in range(min(num_to_pad, len(fallback_segments))):
                    fallback_seg = fallback_segments[i].copy()
                    fallback_seg['reason'] = "ì œí’ˆê³¼ ê´€ë ¨ì„±ì´ ë†’ì€ ê¸°ë³¸ ì„¸ê·¸ë¨¼íŠ¸ì…ë‹ˆë‹¤."
                    fallback_seg['confidence_score'] = 60 # ê¸°ë³¸ ì¶”ì²œ ì ìˆ˜
                    fallback_seg['key_factors'] = ["ê¸°ë³¸ ì¶”ì²œ"]
                    final_recommendations.append(fallback_seg)
            
            st.success(f"âœ… AI íƒ€ê²Ÿ ë¶„ì„ ì™„ë£Œ! (ì´ {len(final_recommendations)}ê°œ í›„ë³´ ì¤‘ ìƒìœ„ {num_recommendations}ê°œ)")
            
            return final_recommendations[:num_recommendations]

        except Exception as e:
            st.error(f"âŒ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return []
    
    def _fetch_url_content(self, url: str) -> str:
        try:
            headers = {'User-Agent': 'Mozilla/5.0'}
            response = requests.get(url, headers=headers, timeout=5)
            response.raise_for_status()
            soup = BeautifulSoup(response.text, 'html.parser')
            meta_desc = soup.find('meta', attrs={'name': 'description'})
            if meta_desc and meta_desc.get('content'):
                return meta_desc.get('content').strip()
            for tag in soup.find_all(['main', 'article']):
                text = tag.get_text(separator=' ', strip=True)
                if len(text) > 100:
                    return text[:1500]
            body_text = soup.body.get_text(separator=' ', strip=True)
            return body_text[:1500]
        except:
            return ""

    def _get_mapping_and_understanding(self, product_name: str, website_url: str, scraped_text: str, db_keywords_list_str: str) -> Dict:
        """
        (â˜…ì‹ ê·œ) 0ë‹¨ê³„: ì œí’ˆ ì´í•´ + í‚¤ì›Œë“œ ë§¤í•‘
        """
        prompt = get_mapping_and_understanding_prompt(
            product_name, website_url, scraped_text, db_keywords_list_str
        )
        
        try:
            raw_response_text = self._generate_with_retry(prompt)
        except Exception as e:
            st.error(f"âŒ Gemini API 0ë‹¨ê³„(ë§¤í•‘) í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
            return {}
        
        try:
            cleaned_text = raw_response_text.strip().replace("```json\n", "").replace("\n```", "").strip()
            parsed_data = json.loads(cleaned_text)
            
            if not isinstance(parsed_data, dict) or "product_understanding" not in parsed_data:
                raise ValueError("AI ì‘ë‹µì´ 0ë‹¨ê³„ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
            
            return parsed_data
        
        except json.JSONDecodeError:
            st.error(f"âŒ AIê°€ 0ë‹¨ê³„ì—ì„œ ìœ íš¨í•˜ì§€ ì•Šì€ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí–ˆìŠµë‹ˆë‹¤: {cleaned_text}")
            return {}
        except ValueError as e:
            st.error(f"âŒ AI 0ë‹¨ê³„ ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
            return {}

    def _filter_with_gemini(self, product_understanding: str, remaining_segments: List[Dict], num_to_filter: int) -> List[str]:
        """
        (â˜…ìˆ˜ì •) 1ë‹¨ê³„: í•„í„°ë§. Bê¸‰ í›„ë³´ ì„ ë³„
        """
        if not remaining_segments or num_to_filter <= 0:
            return []
        
        segments_with_desc = [
            f"- {seg.get('name', 'N/A')} (ì„¤ëª…: {seg.get('description', 'N/A')})"
            for seg in remaining_segments
        ]
        segments_list_str = "\n".join(segments_with_desc)
        
        prompt = get_segment_filtering_prompt(
            product_understanding, 
            segments_list_str, 
            num_to_filter=num_to_filter
        )
        
        try:
            raw_response_text = self._generate_with_retry(prompt)
        except Exception as e:
            st.error(f"âŒ Gemini API 1ë‹¨ê³„(í•„í„°ë§) í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
            return []
        
        try:
            cleaned_text = raw_response_text.strip().replace("```json\n", "").replace("\n```", "").strip()
            parsed_data = json.loads(cleaned_text)
            
            if not isinstance(parsed_data, dict) or "candidate_segments" not in parsed_data:
                raise ValueError("AI ì‘ë‹µì´ 1ë‹¨ê³„ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤. ('candidate_segments' í‚¤ ë¶€ì¬)")
            
            candidate_names = parsed_data.get("candidate_segments", [])
            if not isinstance(candidate_names, list):
                 raise ValueError("AI ì‘ë‹µ 'candidate_segments'ê°€ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
                 
            return [str(name) for name in candidate_names] 
        
        except json.JSONDecodeError:
            st.error(f"âŒ AIê°€ 1ë‹¨ê³„ì—ì„œ ìœ íš¨í•˜ì§€ ì•Šì€ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí–ˆìŠµë‹ˆë‹¤: {cleaned_text}")
            return []
        except ValueError as e:
            st.error(f"âŒ AI 1ë‹¨ê³„ ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
            return []

    def _recommend_with_gemini(self, product_understanding: str, candidate_segments_info: List[Dict], num_to_recommend: int) -> Dict:
        """
        (â˜…ìˆ˜ì •) 2ë‹¨ê³„: ì¬ì •ë ¬. A+B í›„ë³´ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ ìµœì¢… ìˆœìœ„ ê²°ì •
        """
        if not candidate_segments_info:
            return {}
        
        segments_with_desc = []
        for seg in candidate_segments_info: 
            seg_str = f"- {seg.get('name', 'N/A')} (ì„¤ëª…: {seg.get('description', 'N/A')}"
            
            advertisers = seg.get('recommended_advertisers')
            if advertisers and pd.notna(advertisers):
                clean_advertisers = str(advertisers).replace('\n', ', ')
                seg_str += f", ì¶”ì²œ ê´‘ê³ ì£¼: {clean_advertisers}"
            seg_str += ")"
            segments_with_desc.append(seg_str)
        
        segments_list_str = "\n".join(segments_with_desc)
        
        prompt = get_segment_recommendation_prompt(
            product_understanding, 
            segments_list_str, 
            num_to_recommend=num_to_recommend
        )
        
        try:
            raw_response_text = self._generate_with_retry(prompt)
        except Exception as e:
            st.error(f"âŒ Gemini API 2ë‹¨ê³„(ì¬ì •ë ¬) í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
            return {}
        
        try:
            cleaned_text = raw_response_text.strip().replace("```json\n", "").replace("\n```", "").strip()
            parsed_data = json.loads(cleaned_text)
            if not isinstance(parsed_data, dict):
                raise ValueError("AI ì‘ë‹µì´ 2ë‹¨ê³„ ë”•ì…”ë„ˆë¦¬ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
            return parsed_data
        except json.JSONDecodeError:
            st.error(f"âŒ AIê°€ 2ë‹¨ê³„ì—ì„œ ìœ íš¨í•˜ì§€ ì•Šì€ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí–ˆìŠµë‹ˆë‹¤: {cleaned_text}")
            return {}
    
    def _get_segments_by_names(self, segment_names: List[str], available_segments: List[Dict]) -> List[Dict]:
        """ì´ë¦„ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ì„œ ì „ì²´ ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ê°€ ë‹´ê¸´ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
        recommended_segments = []
        available_names_map = {seg['name']: seg for seg in available_segments}
        
        for name in segment_names:
            if name in available_names_map:
                recommended_segments.append(available_names_map[name].copy())
        return recommended_segments
    
    # [â˜…ì‹ ê·œ] 'Aê¸‰ í›„ë³´'ë¥¼ ì„ ë³„í•˜ê³ , ë‚˜ë¨¸ì§€ë¥¼ ë°˜í™˜í•˜ëŠ” í—¬í¼
    def _get_a_class_segments(self, mapped_keywords: List[str], all_segments_info: List[Dict]) -> (List[Dict], List[Dict]):
        if not mapped_keywords:
            return [], all_segments_info

        a_class_segments = []
        remaining_segments = []
        a_class_names = set() # ì¤‘ë³µ ë°©ì§€

        for segment in all_segments_info:
            found = False
            seg_name = segment.get('name', '')
            seg_desc = segment.get('description', '')
            seg_adv = str(segment.get('recommended_advertisers', ''))

            # 'name', 'description', 'recommended_advertisers' ì¤‘ í•˜ë‚˜ë¼ë„ ë§¤í•‘ëœ í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ë©´ Aê¸‰
            for keyword in mapped_keywords:
                if (keyword in seg_name) or (keyword in seg_desc) or (keyword in seg_adv):
                    if seg_name not in a_class_names:
                        a_class_segments.append(segment)
                        a_class_names.add(seg_name)
                    found = True
                    break # ì´ ì„¸ê·¸ë¨¼íŠ¸ëŠ” Aê¸‰ í™•ì •ì´ë¯€ë¡œ ë‹¤ìŒ í‚¤ì›Œë“œ ê²€ì‚¬ ë¶ˆí•„ìš”
            
            if not found:
                remaining_segments.append(segment)

        return a_class_segments, remaining_segments

    # [â˜…ì‹ ê·œ] segments.jsonì—ì„œ DB í‚¤ì›Œë“œ ëª©ë¡ì„ ì¶”ì¶œí•˜ëŠ” í—¬í¼
    def _extract_db_keywords(self, all_segments_info: List[Dict]) -> Set[str]:
        keywords = set()
        for segment in all_segments_info:
            # 1. 'name' ìì²´ë¥¼ í‚¤ì›Œë“œë¡œ ì¶”ê°€
            name = segment.get('name')
            if name and pd.notna(name):
                keywords.add(name.strip())

            # 2. 'recommended_advertisers'ë¥¼ íŒŒì‹±í•˜ì—¬ í‚¤ì›Œë“œë¡œ ì¶”ê°€
            advertisers = segment.get('recommended_advertisers')
            if advertisers and pd.notna(advertisers):
                # "ìë™ì°¨ ë¸Œëœë“œ, ì—¬í–‰ì‚¬/ê´€ê´‘ì²­" -> "ìë™ì°¨ ë¸Œëœë“œ", "ì—¬í–‰ì‚¬", "ê´€ê´‘ì²­"
                # "ìë™ì°¨"ì™€ "ë¸Œëœë“œ"ë¡œ ë¶„ë¦¬í•˜ëŠ” ê²ƒì€ ë„ˆë¬´ ê³¼í•  ìˆ˜ ìˆìŒ
                # ì‰¼í‘œ, ìŠ¬ë˜ì‹œ, ì¤„ë°”ê¿ˆ ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬
                split_keywords = re.split(r'[,/\n]', str(advertisers))
                for kw in split_keywords:
                    cleaned_kw = kw.strip()
                    if cleaned_kw and len(cleaned_kw) > 1: # í•œ ê¸€ìì§œë¦¬ ë²„ë¦¬ê¸°
                        keywords.add(cleaned_kw)
        
        # 'ìƒëª…ë³´í—˜', 'ì†í•´ë³´í—˜' ê°™ì€ êµ¬ì²´ì ì¸ í‚¤ì›Œë“œë§Œ ë‚¨ê¹€
        # (ì˜ˆ: 'ë°', 'ë“±', 'ê³ ê°' ê°™ì€ ì¼ë°˜ ëª…ì‚¬ ì œì™¸ - ì—¬ê¸°ì„œëŠ” ê¸¸ì´ë¡œë§Œ ê°„ë‹¨íˆ í•„í„°ë§)
        return {kw for kw in keywords if len(kw) > 1}


    def _get_available_segments_info(self) -> List[Dict]:
        """ìƒˆ 4-Depth JSON êµ¬ì¡°ë¥¼ íŒŒì‹±í•˜ë„ë¡ ìˆ˜ì •"""
        if 'data' not in self.segments_data or not isinstance(self.segments_data['data'], list):
            return []
            
        segments_info = []
        for segment in self.segments_data['data']:
            if not isinstance(segment, dict):
                continue
            
            cat1 = segment.get('ëŒ€ë¶„ë¥˜')
            cat2 = segment.get('ì¤‘ë¶„ë¥˜')
            cat3 = segment.get('ì†Œë¶„ë¥˜')
            name = segment.get('name', 'N/A')
            
            if cat3 and pd.notna(cat3) and str(cat3).lower() != 'null':
                full_path = f"{cat1} > {cat2} > {cat3} > {name}"
            else:
                full_path = f"{cat1} > {cat2} > {name}"

            seg_copy = segment.copy()
            seg_copy['full_path'] = full_path
            seg_copy['description'] = segment.get('description', '')
            seg_copy['recommended_advertisers'] = segment.get('recommended_advertisers', '')
            
            segments_info.append(seg_copy)
            
        return segments_info
    
    def display_recommendations(self, recommended_segments: List[Dict]):
        """ì¶”ì²œ ê²°ê³¼ í‘œì‹œ"""
        if not recommended_segments:
            st.warning("âŒ ì¶”ì²œí•  ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return
        
        st.markdown("""
        <style>
        .tag-box {
            display: inline-block;
            background-color: #28a745;
            color: white;
            padding: 3px 10px;
            border-radius: 15px;
            font-size: 0.9em;
            font-weight: bold;
            margin-right: 5px;
            margin-top: 5px;
            margin-bottom: 5px;
        }
        </style>
        """, unsafe_allow_html=True)

        for i, segment in enumerate(recommended_segments, 1):
            score = float(segment.get('confidence_score', 0)) 
            
            title_text = f"**{i}. {segment.get('full_path', segment.get('name', 'N/A'))}**"
            
            if score <= 60: 
                 title_text += " (ê¸°ë³¸ ì¶”ì²œ)"

            with st.expander(title_text, expanded=True):
                
                if score > 60:
                    st.markdown(f"**ì í•©ë„: <span style='color:#d9534f; font-weight:bold; font-size: 1.1em;'>{score:.0f}ì </span>**", unsafe_allow_html=True)
                    reason_prefix = "ğŸ’¡ AI ì¶”ì²œ ì‚¬ìœ :"
                else:
                    st.markdown(f"**ì í•©ë„:** {score:.0f}ì ")
                    reason_prefix = "â„¹ï¸ ê¸°ë³¸ ì¶”ì²œ ì‚¬ìœ :"
                
                if segment.get('description'):
                    st.write(f"**ğŸ“‹ ì„¤ëª…:** {segment['description']}")

                if segment.get('key_factors'):
                    tags_html = "".join([f"<span class='tag-box'>{factor}</span>" for factor in segment['key_factors']])
                    st.markdown(f"**ğŸ”‘ í•µì‹¬ ë§¤ì¹­ ìš”ì†Œ:** {tags_html}", unsafe_allow_html=True)

                st.divider()

                if segment.get('reason'):
                    if score > 60:
                        st.success(f"**{reason_prefix}** {segment['reason']}")
                    else:
                        st.info(f"**{reason_prefix}** {segment['reason']}")