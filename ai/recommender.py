# ai/recommender.py
import streamlit as st
import google.generativeai as genai
import os
from typing import List, Dict
import json
from dotenv import load_dotenv
import requests 
from bs4 import BeautifulSoup 
from ai.prompts import get_segment_recommendation_prompt, get_segment_filtering_prompt
import pandas as pd
import time # 429 ì˜¤ë¥˜(ì¬ì‹œë„/ì§€ì—°) ë°©ì§€ë¥¼ ìœ„í•´ time ì„í¬íŠ¸

load_dotenv()

class AISegmentRecommender:
    def __init__(self, data_manager):
        self.data_manager = data_manager
        self.segments_data = data_manager.load_segments()
        self.api_key = os.getenv('GEMINI_API_KEY')
        self.model = None
        self.gemini_available = False
        self._initialize_gemini()
    
    def _initialize_gemini(self):
        if not self.api_key:
            st.error("âŒ Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— GEMINI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
            return
        try:
            genai.configure(api_key=self.api_key)
            try:
                # [â˜…ìˆ˜ì •] 404 ì˜¤ë¥˜ í•´ê²°: 'models/' ì ‘ë‘ì‚¬ ì œê±° (ì‚¬ì¥ë‹˜ ì§€ì‹œ)
                # 1ìˆœìœ„: 'ê°€ì¥ ë¹ ë¥¸ 2.0 flash'
                self.model = genai.GenerativeModel('gemini-2.0-flash')
            except:
                # [â˜…ìˆ˜ì •] 1ìˆœìœ„ ì‹¤íŒ¨ ì‹œ 2ìˆœìœ„: 'pro'
                self.model = genai.GenerativeModel('gemini-2.0-pro')
            self.gemini_available = True
            st.success(f"âœ… AI ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {self.model.model_name}")
        except Exception as e:
            st.error(f"âŒ Gemini API ì„¤ì • ì˜¤ë¥˜: {str(e)}")
            st.error("ai/recommender.py 32~37 ë¼ì¸ì˜ ëª¨ë¸ ì´ë¦„ì„ 'gemini-2.0-flash' / 'gemini-2.0-pro'ë¡œ í™•ì¸í•˜ì„¸ìš”.")
            self.gemini_available = False

    def _generate_with_retry(self, prompt: str, max_retries: int = 3) -> str:
        """
        (â˜…ì‹ ê·œ) Gemini API í˜¸ì¶œ ì‹œ 429 ì˜¤ë¥˜(í• ë‹¹ëŸ‰)ê°€ ë°œìƒí•˜ë©´
        ìë™ìœ¼ë¡œ ì¬ì‹œë„í•˜ëŠ” ë¡œì§ (Exponential Backoff)
        """
        retries = 0
        while retries < max_retries:
            try:
                # [â˜…ì°¸ê³ ] generate_content() í•¨ìˆ˜ë¥¼ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤.
                response = self.model.generate_content(prompt)
                if not response or not response.text:
                    raise ValueError("Gemini APIì—ì„œ ë¹ˆ ì‘ë‹µì„ ë°›ì•˜ìŠµë‹ˆë‹¤.")
                return response.text # ì„±ê³µ ì‹œ ì‘ë‹µ í…ìŠ¤íŠ¸ ë°˜í™˜
            
            except Exception as e:
                # 429 ì˜¤ë¥˜ì´ê³ , ì¬ì‹œë„ íšŸìˆ˜ê°€ ë‚¨ì•˜ì„ ë•Œ
                if "429 Resource exhausted" in str(e) and retries < max_retries - 1:
                    retries += 1
                    wait_time = 2 ** retries # 2ì´ˆ, 4ì´ˆ, 8ì´ˆ...
                    st.warning(f"âš ï¸ API í• ë‹¹ëŸ‰(429) ì´ˆê³¼. {wait_time}ì´ˆ í›„ ì¬ì‹œë„... ({retries}/{max_retries})")
                    time.sleep(wait_time)
                else:
                    # 429ê°€ ì•„ë‹ˆê±°ë‚˜, ë§ˆì§€ë§‰ ì¬ì‹œë„ ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ë°œìƒ
                    raise e 
        
        # ì´ê³³ì— ë„ë‹¬í•˜ë©´ ì•ˆ ë˜ì§€ë§Œ, ë§Œì•½ì„ ìœ„í•´
        raise Exception("API í• ë‹¹ëŸ‰ ì´ˆê³¼. ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨.")

    # 2-Stage (í•„í„°ë§ -> ì¬ì •ë ¬) ë°©ì‹ìœ¼ë¡œ ë¡œì§ ì „ë©´ ìˆ˜ì •
    def recommend_segments(self, product_name: str, website_url: str, num_recommendations: int = 3) -> List[Dict]:
        
        if not product_name.strip() and not website_url.strip():
            st.error("âŒ 'ì œí’ˆëª…' ë˜ëŠ” 'ì œí’ˆ URL*'ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return []
            
        if not self.gemini_available or not self.model:
            st.error("âŒ Gemini AIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []
            
        scraped_text = ""
        if website_url:
            with st.spinner(f"ğŸŒ {website_url} ì›¹í˜ì´ì§€ ë¶„ì„ ì¤‘..."):
                scraped_text = self._fetch_url_content(website_url)
                if not scraped_text:
                    st.warning("âš ï¸ ì›¹ì‚¬ì´íŠ¸ ë‚´ìš©ì„ ìë™ìœ¼ë¡œ ì½ì–´ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì œí’ˆëª…/URLë¡œë§Œ ë¶„ì„í•©ë‹ˆë‹¤.")

        try:
            # 1. ëª¨ë“  ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ ë¡œë“œ (140ê°œ)
            all_segments_info = self._get_available_segments_info()
            if not all_segments_info:
                st.error("âŒ ì„¸ê·¸ë¨¼íŠ¸ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (data/segments.json)")
                return []

            st.info(f"ğŸ” AI íƒ€ê²Ÿ ë¶„ì„ ì‹œì‘... (ì´ {len(all_segments_info)}ê°œ ì„¸ê·¸ë¨¼íŠ¸ ëŒ€ìƒ)")

            # --- 1ë‹¨ê³„: í•„í„°ë§ (140ê°œ -> 40ê°œ) ---
            num_to_filter = 40 # 1ë‹¨ê³„ í›„ë³´ ìˆ˜
            with st.spinner(f"ğŸ¤– AI ë¶„ì„ ì¤‘ (1/2): {len(all_segments_info)}ê°œ ì¤‘ {num_to_filter}ê°œ í›„ë³´ ì„ ë³„ ì¤‘..."):
                candidate_names = self._filter_with_gemini(
                    product_name, website_url, scraped_text, 
                    all_segments_info, 
                    num_to_filter=num_to_filter
                )
            
            if not candidate_names:
                st.warning("âš ï¸ AIê°€ 1ë‹¨ê³„ í›„ë³´ë¥¼ ì„ ë³„í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê´€ë ¨ì„± ë†’ì€ 40ê°œë¥¼ ì„ì˜ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                candidate_segments_info = all_segments_info[:num_to_filter] 
            else:
                candidate_segments_info = self._get_segments_by_names(candidate_names, all_segments_info)
            
            st.info(f"âœ… 1ë‹¨ê³„ ë¶„ì„ ì™„ë£Œ. {len(candidate_segments_info)}ê°œ í›„ë³´ ì„ ë³„.")

            # 429 ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•œ 1ì´ˆ "ìˆ¨ ê³ ë¥´ê¸°"
            time.sleep(1) 

            # --- 2ë‹¨ê³„: ì¬ì •ë ¬ (40ê°œ -> 3ê°œ) ---
            with st.spinner(f"ğŸ¤– AI ë¶„ì„ ì¤‘ (2/2): {len(candidate_segments_info)}ê°œ í›„ë³´ ì •ë°€ ë¶„ì„ ë° ìˆœìœ„ ê²°ì • ì¤‘..."):
                ai_response = self._recommend_with_gemini(
                    product_name, website_url, scraped_text,
                    candidate_segments_info,
                    num_to_recommend=num_recommendations
                )

            if not ai_response:
                segments_from_ai = []
            else:
                product_understanding = ai_response.get("product_understanding")
                if product_understanding:
                    st.info(f"**ğŸ’¡ AIê°€ ì´í•´í•œ ì œí’ˆ:** {product_understanding}")
                segments_from_ai = ai_response.get("recommended_segments", [])

            if not segments_from_ai:
                 st.warning("âš ï¸ AIê°€ 2ë‹¨ê³„ ì¶”ì²œ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê¸°ë³¸ ì¶”ì²œì„ ì œê³µí•©ë‹ˆë‹¤.")

            # --- AI ì‘ë‹µ(ì´ë¦„, ì´ìœ , ì ìˆ˜)ê³¼ ì›ë³¸ ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´(ì„¤ëª…, ê²½ë¡œ ë“±)ë¥¼ ë³‘í•© ---
            segment_names_from_ai = [s.get("name") for s in segments_from_ai if s.get("name")]
            enriched_info_map = {
                s.get("name"): {
                    "reason": s.get("reason", "ì¶”ì²œ ì´ìœ ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."),
                    "confidence_score": s.get("confidence_score", 50),
                    "key_factors": s.get("key_factors", [])
                }
                for s in segments_from_ai if s.get("name")
            }
            
            all_recommendations = []
            for name in segment_names_from_ai:
                seg_data = next((s for s in candidate_segments_info if s.get('name') == name), None)
                if seg_data:
                    seg_copy = seg_data.copy()
                    if name in enriched_info_map:
                        seg_copy['reason'] = enriched_info_map[name]['reason']
                        seg_copy['confidence_score'] = float(enriched_info_map[name]['confidence_score'])
                        seg_copy['key_factors'] = enriched_info_map[name]['key_factors']
                    all_recommendations.append(seg_copy)

            # (â˜…ì •ë ¬ ë²„ê·¸ ìˆ˜ì •â˜…) ì ìˆ˜(ìˆ«ì)ë¡œ ë‹¤ì‹œ ì •ë ¬
            all_recommendations.sort(key=lambda x: float(x.get('confidence_score', 0)), reverse=True)
            
            # --- (ê¸°ì¡´ ë¡œì§ ì¬ì‚¬ìš©) ì¤‘ë³µ ì œê±° ë° Fallback ---
            final_recommendations = []
            seen_names = set()
            for seg in all_recommendations:
                if seg['name'] not in seen_names and float(seg.get('confidence_score', 0)) > 50:
                    final_recommendations.append(seg)
                    seen_names.add(seg['name'])

            # 5. Fallback ë¡œì§ (í•„ìš”ì‹œ)
            num_to_pad = num_recommendations - len(final_recommendations)
            if num_to_pad > 0:
                existing_names = [seg['name'] for seg in final_recommendations]
                fallback_segments = [seg for seg in all_segments_info if seg['name'] not in existing_names]
                
                for i in range(min(num_to_pad, len(fallback_segments))):
                    fallback_seg = fallback_segments[i].copy()
                    fallback_seg['reason'] = "ì œí’ˆê³¼ ê´€ë ¨ì„±ì´ ë†’ì€ ê¸°ë³¸ ì„¸ê·¸ë¨¼íŠ¸ì…ë‹ˆë‹¤."
                    fallback_seg['confidence_score'] = 60 # ê¸°ë³¸ ì¶”ì²œ ì ìˆ˜
                    fallback_seg['key_factors'] = ["ê¸°ë³¸ ì¶”ì²œ"]
                    final_recommendations.append(fallback_seg)
            
            st.success(f"âœ… AI íƒ€ê²Ÿ ë¶„ì„ ì™„ë£Œ! (ì´ {len(final_recommendations)}ê°œ í›„ë³´ ì¤‘ ìƒìœ„ {num_recommendations}ê°œ)")
            
            return final_recommendations[:num_recommendations]

        except Exception as e:
            st.error(f"âŒ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return []
    
    def _fetch_url_content(self, url: str) -> str:
        try:
            headers = {'User-Agent': 'Mozilla/5.0'}
            response = requests.get(url, headers=headers, timeout=5)
            response.raise_for_status()
            soup = BeautifulSoup(response.text, 'html.parser')
            meta_desc = soup.find('meta', attrs={'name': 'description'})
            if meta_desc and meta_desc.get('content'):
                return meta_desc.get('content').strip()
            for tag in soup.find_all(['main', 'article']):
                text = tag.get_text(separator=' ', strip=True)
                if len(text) > 100:
                    return text[:1500]
            body_text = soup.body.get_text(separator=' ', strip=True)
            return body_text[:1500]
        except:
            return ""

    def _filter_with_gemini(self, product_name: str, website_url: str, scraped_text: str, all_segments_info: List[Dict], num_to_filter: int) -> List[str]:
        """1ë‹¨ê³„: í•„í„°ë§. ì „ì²´ ì„¸ê·¸ë¨¼íŠ¸ì—ì„œ í›„ë³´ ì´ë¦„ë§Œ 40ê°œ ì¶”ì¶œ"""
        if not all_segments_info:
            return []
        
        segments_with_desc = [
            f"- {seg.get('name', 'N/A')} (ì„¤ëª…: {seg.get('description', 'N/A')})"
            for seg in all_segments_info
        ]
        segments_list_str = "\n".join(segments_with_desc)
        
        prompt = get_segment_filtering_prompt(
            product_name, website_url, scraped_text, 
            segments_list_str, 
            num_to_filter=num_to_filter
        )
        
        try:
            # [â˜…ìˆ˜ì •] ì¬ì‹œë„ ë¡œì§ ì ìš©
            raw_response_text = self._generate_with_retry(prompt)
        except Exception as e:
            st.error(f"âŒ Gemini API 1ë‹¨ê³„(í•„í„°ë§) í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
            return []
        
        try:
            cleaned_text = raw_response_text.strip().replace("```json\n", "").replace("\n```", "").strip()
            parsed_data = json.loads(cleaned_text)
            
            if not isinstance(parsed_data, dict) or "candidate_segments" not in parsed_data:
                raise ValueError("AI ì‘ë‹µì´ 1ë‹¨ê³„ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤. ('candidate_segments' í‚¤ ë¶€ì¬)")
            
            candidate_names = parsed_data.get("candidate_segments", [])
            if not isinstance(candidate_names, list):
                 raise ValueError("AI ì‘ë‹µ 'candidate_segments'ê°€ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
                 
            return [str(name) for name in candidate_names] # ì´ë¦„ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        
        except json.JSONDecodeError:
            st.error(f"âŒ AIê°€ 1ë‹¨ê³„ì—ì„œ ìœ íš¨í•˜ì§€ ì•Šì€ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí–ˆìŠµë‹ˆë‹¤: {cleaned_text}")
            return []
        except ValueError as e:
            st.error(f"âŒ AI 1ë‹¨ê³„ ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
            return []

    def _recommend_with_gemini(self, product_name: str, website_url: str, scraped_text: str, candidate_segments_info: List[Dict], num_to_recommend: int) -> Dict:
        """2ë‹¨ê³„: ì¬ì •ë ¬. 40ê°œ í›„ë³´ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ ìµœì¢… 3~10ê°œ ì¶”ì²œ"""
        if not candidate_segments_info:
            return {}
        
        segments_with_desc = []
        for seg in candidate_segments_info: 
            seg_str = f"- {seg.get('name', 'N/A')} (ì„¤ëª…: {seg.get('description', 'N/A')}"
            
            advertisers = seg.get('recommended_advertisers')
            if advertisers and pd.notna(advertisers):
                clean_advertisers = str(advertisers).replace('\n', ', ')
                seg_str += f", ì¶”ì²œ ê´‘ê³ ì£¼: {clean_advertisers}"
            seg_str += ")"
            segments_with_desc.append(seg_str)
        
        segments_list_str = "\n".join(segments_with_desc)
        
        prompt = get_segment_recommendation_prompt(
            product_name, website_url, scraped_text, segments_list_str, 
            num_to_recommend=num_to_recommend
        )
        
        try:
            # [â˜…ìˆ˜ì •] ì¬ì‹œë„ ë¡œì§ ì ìš©
            raw_response_text = self._generate_with_retry(prompt)
        except Exception as e:
            # 2ë‹¨ê³„ ì‹¤íŒ¨ëŠ” ì‚¬ìš©ìê°€ ë³¸ ì—ëŸ¬ì´ë¯€ë¡œ st.errorë¡œ í‘œì‹œ
            st.error(f"âŒ Gemini API 2ë‹¨ê³„(ì¬ì •ë ¬) í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
            return {}
        
        try:
            cleaned_text = raw_response_text.strip().replace("```json\n", "").replace("\n```", "").strip()
            parsed_data = json.loads(cleaned_text)
            if not isinstance(parsed_data, dict):
                raise ValueError("AI ì‘ë‹µì´ 2ë‹¨ê³„ ë”•ì…”ë„ˆë¦¬ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
            return parsed_data
        except json.JSONDecodeError:
            st.error(f"âŒ AIê°€ 2ë‹¨ê³„ì—ì„œ ìœ íš¨í•˜ì§€ ì•Šì€ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí–ˆìŠµë‹ˆë‹¤: {cleaned_text}")
            return {}
    
    def _get_segments_by_names(self, segment_names: List[str], available_segments: List[Dict]) -> List[Dict]:
        """ì´ë¦„ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ì„œ ì „ì²´ ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ê°€ ë‹´ê¸´ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
        recommended_segments = []
        available_names_map = {seg['name']: seg for seg in available_segments}
        
        for name in segment_names:
            if name in available_names_map:
                recommended_segments.append(available_names_map[name].copy())
        return recommended_segments
    
    def _get_available_segments_info(self) -> List[Dict]:
        """ìƒˆ 4-Depth JSON êµ¬ì¡°ë¥¼ íŒŒì‹±í•˜ë„ë¡ ìˆ˜ì •"""
        if 'data' not in self.segments_data or not isinstance(self.segments_data['data'], list):
            return []
            
        segments_info = []
        for segment in self.segments_data['data']:
            if not isinstance(segment, dict):
                continue
            
            cat1 = segment.get('ëŒ€ë¶„ë¥˜')
            cat2 = segment.get('ì¤‘ë¶„ë¥˜')
            cat3 = segment.get('ì†Œë¶„ë¥˜')
            name = segment.get('name', 'N/A')
            
            if cat3 and pd.notna(cat3) and str(cat3).lower() != 'null':
                full_path = f"{cat1} > {cat2} > {cat3} > {name}"
            else:
                full_path = f"{cat1} > {cat2} > {name}"

            seg_copy = segment.copy()
            seg_copy['full_path'] = full_path
            seg_copy['description'] = segment.get('description', '')
            seg_copy['recommended_advertisers'] = segment.get('recommended_advertisers', '')
            
            segments_info.append(seg_copy)
            
        return segments_info
    
    def display_recommendations(self, recommended_segments: List[Dict]):
        """ì¶”ì²œ ê²°ê³¼ í‘œì‹œ"""
        if not recommended_segments:
            st.warning("âŒ ì¶”ì²œí•  ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return
        
        st.markdown("""
        <style>
        .tag-box {
            display: inline-block;
            background-color: #28a745;
            color: white;
            padding: 3px 10px;
            border-radius: 15px;
            font-size: 0.9em;
            font-weight: bold;
            margin-right: 5px;
            margin-top: 5px;
            margin-bottom: 5px;
        }
        </style>
        """, unsafe_allow_html=True)

        for i, segment in enumerate(recommended_segments, 1):
            score = float(segment.get('confidence_score', 0)) 
            
            title_text = f"**{i}. {segment.get('full_path', segment.get('name', 'N/A'))}**"
            
            if score <= 60: 
                 title_text += " (ê¸°ë³¸ ì¶”ì²œ)"

            with st.expander(title_text, expanded=True):
                
                if score > 60:
                    st.markdown(f"**ì í•©ë„: <span style='color:#d9534f; font-weight:bold; font-size: 1.1em;'>{score:.0f}ì </span>**", unsafe_allow_html=True)
                    reason_prefix = "ğŸ’¡ AI ì¶”ì²œ ì‚¬ìœ :"
                else:
                    st.markdown(f"**ì í•©ë„:** {score:.0f}ì ")
                    reason_prefix = "â„¹ï¸ ê¸°ë³¸ ì¶”ì²œ ì‚¬ìœ :"
                
                if segment.get('description'):
                    st.write(f"**ğŸ“‹ ì„¤ëª…:** {segment['description']}")

                if segment.get('key_factors'):
                    tags_html = "".join([f"<span class='tag-box'>{factor}</span>" for factor in segment['key_factors']])
                    st.markdown(f"**ğŸ”‘ í•µì‹¬ ë§¤ì¹­ ìš”ì†Œ:** {tags_html}", unsafe_allow_html=True)

                st.divider()

                if segment.get('reason'):
                    if score > 60:
                        st.success(f"**{reason_prefix}** {segment['reason']}")
                    else:
                        st.info(f"**{reason_prefix}** {segment['reason']}")