# ai/recommender.py
import streamlit as st
import google.generativeai as genai
import os
from typing import List, Dict
import json
from dotenv import load_dotenv
import requests 
from bs4 import BeautifulSoup 
from ai.prompts import get_segment_recommendation_prompt, get_segment_filtering_prompt # [â˜…ìˆ˜ì •] 1ë‹¨ê³„ í”„ë¡¬í”„íŠ¸ ì„í¬íŠ¸
import pandas as pd

load_dotenv()

class AISegmentRecommender:
    def __init__(self, data_manager):
        self.data_manager = data_manager
        self.segments_data = data_manager.load_segments()
        self.api_key = os.getenv('GEMINI_API_KEY')
        self.model = None
        self.gemini_available = False
        self._initialize_gemini()
    
    def _initialize_gemini(self):
        if not self.api_key:
            st.error("âŒ Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— GEMINI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
            return
        try:
            genai.configure(api_key=self.api_key)
            try:
                self.model = genai.GenerativeModel('gemini-2.0-flash')
            except:
                self.model = genai.GenerativeModel('gemini-pro')
            self.gemini_available = True
        except Exception as e:
            st.error(f"âŒ Gemini API ì„¤ì • ì˜¤ë¥˜: {str(e)}")
            self.gemini_available = False
    
    # [â˜…ìˆ˜ì •] 2-Stage (í•„í„°ë§ -> ì¬ì •ë ¬) ë°©ì‹ìœ¼ë¡œ ë¡œì§ ì „ë©´ ìˆ˜ì •
    def recommend_segments(self, product_name: str, website_url: str, num_recommendations: int = 3) -> List[Dict]:
        
        if not product_name.strip() and not website_url.strip():
            st.error("âŒ 'ì œí’ˆëª…' ë˜ëŠ” 'ì œí’ˆ URL*'ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return []
            
        if not self.gemini_available or not self.model:
            st.error("âŒ Gemini AIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []
            
        scraped_text = ""
        if website_url:
            with st.spinner(f"ğŸŒ {website_url} ì›¹í˜ì´ì§€ ë¶„ì„ ì¤‘..."):
                scraped_text = self._fetch_url_content(website_url)
                if not scraped_text:
                    st.warning("âš ï¸ ì›¹ì‚¬ì´íŠ¸ ë‚´ìš©ì„ ìë™ìœ¼ë¡œ ì½ì–´ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì œí’ˆëª…/URLë¡œë§Œ ë¶„ì„í•©ë‹ˆë‹¤.")

        try:
            # 1. ëª¨ë“  ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ ë¡œë“œ (140ê°œ)
            all_segments_info = self._get_available_segments_info()
            if not all_segments_info:
                st.error("âŒ ì„¸ê·¸ë¨¼íŠ¸ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (data/segments.json)")
                return []

            st.info(f"ğŸ” AI íƒ€ê²Ÿ ë¶„ì„ ì‹œì‘... (ì´ {len(all_segments_info)}ê°œ ì„¸ê·¸ë¨¼íŠ¸ ëŒ€ìƒ)")

            # --- 1ë‹¨ê³„: í•„í„°ë§ (140ê°œ -> 40ê°œ) ---
            num_to_filter = 40 # 1ë‹¨ê³„ í›„ë³´ ìˆ˜
            with st.spinner(f"ğŸ¤– AI ë¶„ì„ ì¤‘ (1/2): {len(all_segments_info)}ê°œ ì¤‘ {num_to_filter}ê°œ í›„ë³´ ì„ ë³„ ì¤‘..."):
                candidate_names = self._filter_with_gemini(
                    product_name, website_url, scraped_text, 
                    all_segments_info, 
                    num_to_filter=num_to_filter
                )
            
            if not candidate_names:
                st.warning("âš ï¸ AIê°€ 1ë‹¨ê³„ í›„ë³´ë¥¼ ì„ ë³„í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê´€ë ¨ì„± ë†’ì€ 40ê°œë¥¼ ì„ì˜ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                # ë¹„ìƒì‹œ ê·¸ëƒ¥ ì• 40ê°œ ì‚¬ìš© (í˜¹ì€ ë‹¤ë¥¸ ë¡œì§)
                candidate_segments_info = all_segments_info[:num_to_filter] 
            else:
                # AIê°€ ë°˜í™˜í•œ ì´ë¦„(40ê°œ)ì— í•´ë‹¹í•˜ëŠ” 'ì „ì²´ ì •ë³´'ë¥¼ ë‹¤ì‹œ ë§¤ì¹­
                candidate_segments_info = self._get_segments_by_names(candidate_names, all_segments_info)
            
            st.info(f"âœ… 1ë‹¨ê³„ ë¶„ì„ ì™„ë£Œ. {len(candidate_segments_info)}ê°œ í›„ë³´ ì„ ë³„.")

            # --- 2ë‹¨ê³„: ì¬ì •ë ¬ (40ê°œ -> 3ê°œ) ---
            with st.spinner(f"ğŸ¤– AI ë¶„ì„ ì¤‘ (2/2): {len(candidate_segments_info)}ê°œ í›„ë³´ ì •ë°€ ë¶„ì„ ë° ìˆœìœ„ ê²°ì • ì¤‘..."):
                ai_response = self._recommend_with_gemini(
                    product_name, website_url, scraped_text,
                    candidate_segments_info, # [â˜…ìˆ˜ì •] ì „ì²´(140)ê°€ ì•„ë‹Œ í›„ë³´(40) ë¦¬ìŠ¤íŠ¸ ì „ë‹¬
                    num_to_recommend=num_recommendations # ì‚¬ìš©ìê°€ ìš”ì²­í•œ ìµœì¢… ê°œìˆ˜
                )

            if not ai_response:
                segments_from_ai = []
            else:
                product_understanding = ai_response.get("product_understanding")
                if product_understanding:
                    st.info(f"**ğŸ’¡ AIê°€ ì´í•´í•œ ì œí’ˆ:** {product_understanding}")
                segments_from_ai = ai_response.get("recommended_segments", [])

            if not segments_from_ai:
                 st.warning("âš ï¸ AIê°€ 2ë‹¨ê³„ ì¶”ì²œ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê¸°ë³¸ ì¶”ì²œì„ ì œê³µí•©ë‹ˆë‹¤.")

            # --- AI ì‘ë‹µ(ì´ë¦„, ì´ìœ , ì ìˆ˜)ê³¼ ì›ë³¸ ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´(ì„¤ëª…, ê²½ë¡œ ë“±)ë¥¼ ë³‘í•© ---
            segment_names_from_ai = [s.get("name") for s in segments_from_ai if s.get("name")]
            enriched_info_map = {
                s.get("name"): {
                    "reason": s.get("reason", "ì¶”ì²œ ì´ìœ ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."),
                    "confidence_score": s.get("confidence_score", 50),
                    "key_factors": s.get("key_factors", [])
                }
                for s in segments_from_ai if s.get("name")
            }
            
            # AIê°€ ì¶”ì²œí•œ ìˆœì„œ + ì •ë³´ë¡œ ìµœì¢… ë¦¬ìŠ¤íŠ¸ ìƒì„±
            all_recommendations = []
            for name in segment_names_from_ai:
                # 40ê°œ í›„ë³´ ë¦¬ìŠ¤íŠ¸(candidate_segments_info)ì—ì„œ ì›ë³¸ ë°ì´í„° ì°¾ê¸°
                seg_data = next((s for s in candidate_segments_info if s.get('name') == name), None)
                if seg_data:
                    seg_copy = seg_data.copy()
                    if name in enriched_info_map:
                        seg_copy['reason'] = enriched_info_map[name]['reason']
                        # (â˜…ì •ë ¬ ë²„ê·¸ ìˆ˜ì •â˜…) ì ìˆ˜ë¥¼ floatìœ¼ë¡œ ì €ì¥
                        seg_copy['confidence_score'] = float(enriched_info_map[name]['confidence_score'])
                        seg_copy['key_factors'] = enriched_info_map[name]['key_factors']
                    all_recommendations.append(seg_copy)

            # --- (â˜…ì •ë ¬ ë²„ê·¸ ìˆ˜ì •â˜…) ---
            # AIê°€ ë°˜í™˜í•œ ìˆœì„œë¥¼ ì¡´ì¤‘í•˜ë˜, ë§Œì•½ì„ ëŒ€ë¹„í•´ ì ìˆ˜(ìˆ«ì)ë¡œ ë‹¤ì‹œ ì •ë ¬
            # 100ì ì´ ì—†ì–´ë„ ë’¤ì£½ë°•ì£½ì¸ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ float()ë¡œ ê°•ì œ í˜•ë³€í™˜
            all_recommendations.sort(key=lambda x: float(x.get('confidence_score', 0)), reverse=True)
            
            # --- (ê¸°ì¡´ ë¡œì§ ì¬ì‚¬ìš©) ì¤‘ë³µ ì œê±° ë° Fallback ---
            final_recommendations = []
            seen_names = set()
            for seg in all_recommendations:
                # ì ìˆ˜ê°€ 50 (ê¸°ë³¸ê°’)ì´ ì•„ë‹Œ, AIê°€ ìƒì„±í•œ ìœ íš¨í•œ ì¶”ì²œë§Œ ë¨¼ì € ì¶”ê°€
                if seg['name'] not in seen_names and float(seg.get('confidence_score', 0)) > 50:
                    final_recommendations.append(seg)
                    seen_names.add(seg['name'])

            # 5. Fallback ë¡œì§ (í•„ìš”ì‹œ)
            num_to_pad = num_recommendations - len(final_recommendations)
            if num_to_pad > 0:
                # Fallback í›„ë³´ëŠ” AIê°€ ì¶”ì²œí•˜ì§€ ì•Šì€ *ì „ì²´* ì„¸ê·¸ë¨¼íŠ¸ì—ì„œ ì°¾ì•„ì•¼ í•¨
                existing_names = [seg['name'] for seg in final_recommendations]
                fallback_segments = [seg for seg in all_segments_info if seg['name'] not in existing_names]
                
                # Fallback í›„ë³´ë„ ì ìˆ˜ìˆœ(ê¸°ë³¸ê°’)ì´ë‚˜ ë‹¤ë¥¸ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ë©´ ì¢‹ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœ ì¶”ê°€
                for i in range(min(num_to_pad, len(fallback_segments))):
                    fallback_seg = fallback_segments[i].copy()
                    fallback_seg['reason'] = "ì œí’ˆê³¼ ê´€ë ¨ì„±ì´ ë†’ì€ ê¸°ë³¸ ì„¸ê·¸ë¨¼íŠ¸ì…ë‹ˆë‹¤."
                    fallback_seg['confidence_score'] = 60 # ê¸°ë³¸ ì¶”ì²œ ì ìˆ˜
                    fallback_seg['key_factors'] = ["ê¸°ë³¸ ì¶”ì²œ"]
                    final_recommendations.append(fallback_seg)
            
            st.success(f"âœ… AI íƒ€ê²Ÿ ë¶„ì„ ì™„ë£Œ! (ì´ {len(final_recommendations)}ê°œ í›„ë³´ ì¤‘ ìƒìœ„ {num_recommendations}ê°œ)")
            
            # 6. ìµœì¢… ê°œìˆ˜ë§Œí¼ ì˜ë¼ì„œ ë°˜í™˜
            return final_recommendations[:num_recommendations]

        except Exception as e:
            st.error(f"âŒ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return []
    
    def _fetch_url_content(self, url: str) -> str:
        try:
            headers = {'User-Agent': 'Mozilla/5.0'}
            response = requests.get(url, headers=headers, timeout=5)
            response.raise_for_status()
            soup = BeautifulSoup(response.text, 'html.parser')
            meta_desc = soup.find('meta', attrs={'name': 'description'})
            if meta_desc and meta_desc.get('content'):
                return meta_desc.get('content').strip()
            for tag in soup.find_all(['main', 'article']):
                text = tag.get_text(separator=' ', strip=True)
                if len(text) > 100:
                    return text[:1500]
            body_text = soup.body.get_text(separator=' ', strip=True)
            return body_text[:1500]
        except:
            return ""

    def _filter_with_gemini(self, product_name: str, website_url: str, scraped_text: str, all_segments_info: List[Dict], num_to_filter: int) -> List[str]:
        """(â˜…ì‹ ê·œ) 1ë‹¨ê³„: í•„í„°ë§. ì „ì²´ ì„¸ê·¸ë¨¼íŠ¸ì—ì„œ í›„ë³´ ì´ë¦„ë§Œ 40ê°œ ì¶”ì¶œ"""
        if not all_segments_info:
            return []
        
        # 1ë‹¨ê³„ì—ì„œëŠ” ì„¤ëª…ë§Œ ì œê³µ (ì¶”ì²œ ê´‘ê³ ì£¼ ë“±ì€ ì œì™¸)
        segments_with_desc = [
            f"- {seg.get('name', 'N/A')} (ì„¤ëª…: {seg.get('description', 'N/A')})"
            for seg in all_segments_info
        ]
        segments_list_str = "\n".join(segments_with_desc)
        
        prompt = get_segment_filtering_prompt(
            product_name, website_url, scraped_text, 
            segments_list_str, 
            num_to_filter=num_to_filter
        )
        
        try:
            response = self.model.generate_content(prompt)
            if not response or not response.text:
                raise ValueError("Gemini APIì—ì„œ 1ë‹¨ê³„ ë¹ˆ ì‘ë‹µì„ ë°›ì•˜ìŠµë‹ˆë‹¤.")
            raw_response_text = response.text
        except Exception as e:
            st.error(f"âŒ Gemini API 1ë‹¨ê³„(í•„í„°ë§) í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
            return []
        
        try:
            cleaned_text = raw_response_text.strip().replace("```json\n", "").replace("\n```", "").strip()
            parsed_data = json.loads(cleaned_text)
            
            if not isinstance(parsed_data, dict) or "candidate_segments" not in parsed_data:
                raise ValueError("AI ì‘ë‹µì´ 1ë‹¨ê³„ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤. ('candidate_segments' í‚¤ ë¶€ì¬)")
            
            candidate_names = parsed_data.get("candidate_segments", [])
            if not isinstance(candidate_names, list):
                 raise ValueError("AI ì‘ë‹µ 'candidate_segments'ê°€ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
                 
            return [str(name) for name in candidate_names] # ì´ë¦„ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        
        except json.JSONDecodeError:
            st.error(f"âŒ AIê°€ 1ë‹¨ê³„ì—ì„œ ìœ íš¨í•˜ì§€ ì•Šì€ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí–ˆìŠµë‹ˆë‹¤: {cleaned_text}")
            return []
        except ValueError as e:
            st.error(f"âŒ AI 1ë‹¨ê³„ ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
            return []

    # [â˜…ìˆ˜ì •] ì´ í•¨ìˆ˜ëŠ” ì´ì œ 2ë‹¨ê³„ (ì¬ì •ë ¬)ì„ ë‹´ë‹¹
    def _recommend_with_gemini(self, product_name: str, website_url: str, scraped_text: str, candidate_segments_info: List[Dict], num_to_recommend: int) -> Dict:
        """(â˜…ìˆ˜ì •) 2ë‹¨ê³„: ì¬ì •ë ¬. 40ê°œ í›„ë³´ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ ìµœì¢… 3~10ê°œ ì¶”ì²œ"""
        if not candidate_segments_info:
            # í›„ë³´ ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìœ¼ë©´ ë¹ˆ dict ë°˜í™˜
            return {}
        
        segments_with_desc = []
        for seg in candidate_segments_info: # 40ê°œ í›„ë³´ ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©
            seg_str = f"- {seg.get('name', 'N/A')} (ì„¤ëª…: {seg.get('description', 'N/A')}"
            
            advertisers = seg.get('recommended_advertisers')
            if advertisers and pd.notna(advertisers):
                clean_advertisers = str(advertisers).replace('\n', ', ')
                seg_str += f", ì¶”ì²œ ê´‘ê³ ì£¼: {clean_advertisers}"
            seg_str += ")"
            segments_with_desc.append(seg_str)
        
        segments_list_str = "\n".join(segments_with_desc)
        
        prompt = get_segment_recommendation_prompt(
            product_name, website_url, scraped_text, segments_list_str, 
            num_to_recommend=num_to_recommend
        )
        
        try:
            # 2ë‹¨ê³„ ìŠ¤í”¼ë„ˆëŠ” ì™¸ë¶€(recommend_segments)ì—ì„œ ê´€ë¦¬
            response = self.model.generate_content(prompt)
            if not response or not response.text:
                raise ValueError("Gemini APIì—ì„œ 2ë‹¨ê³„ ë¹ˆ ì‘ë‹µì„ ë°›ì•˜ìŠµë‹ˆë‹¤.")
            raw_response_text = response.text
        except Exception as e:
            # 2ë‹¨ê³„ ì‹¤íŒ¨ëŠ” ì¤‘ìš”í•˜ë¯€ë¡œ st.error
            st.error(f"âŒ Gemini API 2ë‹¨ê³„(ì¬ì •ë ¬) í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
            return {}
        
        try:
            cleaned_text = raw_response_text.strip().replace("```json\n", "").replace("\n```", "").strip()
            parsed_data = json.loads(cleaned_text)
            if not isinstance(parsed_data, dict):
                raise ValueError("AI ì‘ë‹µì´ 2ë‹¨ê³„ ë”•ì…”ë„ˆë¦¬ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
            return parsed_data
        except json.JSONDecodeError:
            st.error(f"âŒ AIê°€ 2ë‹¨ê³„ì—ì„œ ìœ íš¨í•˜ì§€ ì•Šì€ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí–ˆìŠµë‹ˆë‹¤: {cleaned_text}")
            return {}
    
    def _get_segments_by_names(self, segment_names: List[str], available_segments: List[Dict]) -> List[Dict]:
        """ì´ë¦„ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ì„œ ì „ì²´ ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ê°€ ë‹´ê¸´ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
        recommended_segments = []
        available_names_map = {seg['name']: seg for seg in available_segments}
        
        # AIê°€ ë°˜í™˜í•œ ì´ë¦„ ìˆœì„œë¥¼ ìœ ì§€
        for name in segment_names:
            if name in available_names_map:
                recommended_segments.append(available_names_map[name].copy())
        return recommended_segments
    
    def _get_available_segments_info(self) -> List[Dict]:
        """(â˜…ìˆ˜ì •) ìƒˆ 4-Depth JSON êµ¬ì¡°ë¥¼ íŒŒì‹±í•˜ë„ë¡ ìˆ˜ì •"""
        if 'data' not in self.segments_data or not isinstance(self.segments_data['data'], list):
            return []
            
        segments_info = []
        for segment in self.segments_data['data']:
            if not isinstance(segment, dict):
                continue
            
            # CSVì˜ nullì„ Noneìœ¼ë¡œ ì²˜ë¦¬
            cat1 = segment.get('ëŒ€ë¶„ë¥˜')
            cat2 = segment.get('ì¤‘ë¶„ë¥˜')
            cat3 = segment.get('ì†Œë¶„ë¥˜')
            name = segment.get('name', 'N/A')
            
            if cat3 and pd.notna(cat3) and str(cat3).lower() != 'null':
                full_path = f"{cat1} > {cat2} > {cat3} > {name}"
            else:
                full_path = f"{cat1} > {cat2} > {name}"

            # ìƒˆ êµ¬ì¡°ì— ë§ê²Œ ë³µì‚¬
            seg_copy = segment.copy()
            seg_copy['full_path'] = full_path
            # í‚¤ ì´ë¦„ ì¼ê´€ì„± ìœ ì§€ (description, recommended_advertisersëŠ” CSVì™€ ë™ì¼)
            seg_copy['description'] = segment.get('description', '')
            seg_copy['recommended_advertisers'] = segment.get('recommended_advertisers', '')
            
            segments_info.append(seg_copy)
            
        return segments_info
    
    def display_recommendations(self, recommended_segments: List[Dict]):
        """ì¶”ì²œ ê²°ê³¼ í‘œì‹œ (st.expander ì‚¬ìš©, UI ìˆ˜ì •)"""
        if not recommended_segments:
            st.warning("âŒ ì¶”ì²œí•  ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return
        
        st.markdown("""
        <style>
        .tag-box {
            display: inline-block;
            background-color: #28a745;
            color: white;
            padding: 3px 10px;
            border-radius: 15px;
            font-size: 0.9em;
            font-weight: bold;
            margin-right: 5px;
            margin-top: 5px;
            margin-bottom: 5px;
        }
        </style>
        """, unsafe_allow_html=True)

        for i, segment in enumerate(recommended_segments, 1):
            score = float(segment.get('confidence_score', 0)) # (â˜…ì •ë ¬ ë²„ê·¸ ìˆ˜ì •â˜…) floatìœ¼ë¡œ ì½ê¸°
            
            # [â˜…ìˆ˜ì •] full_path í‚¤ ì‚¬ìš©
            title_text = f"**{i}. {segment.get('full_path', segment.get('name', 'N/A'))}**"
            
            if score <= 60: # 60ì  ì´í•˜ëŠ” ê¸°ë³¸ ì¶”ì²œìœ¼ë¡œ ê°„ì£¼
                 title_text += " (ê¸°ë³¸ ì¶”ì²œ)"

            with st.expander(title_text, expanded=True):
                
                if score > 60:
                    st.markdown(f"**ì í•©ë„: <span style='color:#d9534f; font-weight:bold; font-size: 1.1em;'>{score:.0f}ì </span>**", unsafe_allow_html=True)
                    reason_prefix = "ğŸ’¡ AI ì¶”ì²œ ì‚¬ìœ :"
                else:
                    st.markdown(f"**ì í•©ë„:** {score:.0f}ì ")
                    reason_prefix = "â„¹ï¸ ê¸°ë³¸ ì¶”ì²œ ì‚¬ìœ :"
                
                # [â˜…ìˆ˜ì •] description í‚¤ ì‚¬ìš©
                if segment.get('description'):
                    st.write(f"**ğŸ“‹ ì„¤ëª…:** {segment['description']}")

                if segment.get('key_factors'):
                    tags_html = "".join([f"<span class='tag-box'>{factor}</span>" for factor in segment['key_factors']])
                    st.markdown(f"**ğŸ”‘ í•µì‹¬ ë§¤ì¹­ ìš”ì†Œ:** {tags_html}", unsafe_allow_html=True)

                st.divider()

                if segment.get('reason'):
                    if score > 60:
                        st.success(f"**{reason_prefix}** {segment['reason']}")
                    else:
                        st.info(f"**{reason_prefix}** {segment['reason']}")